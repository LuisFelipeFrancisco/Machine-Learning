{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dados = pd.read_csv('data/machine-learning-carros-simulacao.csv')\n",
    "\n",
    "dados = dados.drop(columns=[\"Unnamed: 0\"], axis=1)\n",
    "\n",
    "dados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# situação horrível de \"azar\" onde as classes estão ordenadas por padrão\n",
    "\n",
    "dados_azar = dados.sort_values(\"vendido\", ascending=True)\n",
    "x_azar = dados_azar[[\"preco\", \"idade_do_modelo\",\"km_por_ano\"]]\n",
    "y_azar = dados_azar[\"vendido\"]\n",
    "dados_azar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.dummy import DummyClassifier\n",
    "import numpy as np\n",
    "\n",
    "SEED = 301\n",
    "np.random.seed(SEED)\n",
    "\n",
    "modelo = DummyClassifier()\n",
    "results = cross_validate(modelo, x_azar, y_azar, cv = 10, return_train_score=False)\n",
    "media = results['test_score'].mean()\n",
    "desvio_padrao = results['test_score'].std()\n",
    "print(\"Accuracy com dummy stratified, 10 = [%.2f, %.2f]\" % ((media - 2 * desvio_padrao)*100, (media + 2 * desvio_padrao) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "SEED = 301\n",
    "np.random.seed(SEED)\n",
    "\n",
    "modelo = DecisionTreeClassifier(max_depth=2)\n",
    "results = cross_validate(modelo, x_azar, y_azar, cv = 10, return_train_score=False)\n",
    "media = results['test_score'].mean()\n",
    "desvio_padrao = results['test_score'].std()\n",
    "print(\"Accuracy com cross validation, 10 = [%.2f, %.2f]\" % ((media - 2 * desvio_padrao)*100, (media + 2 * desvio_padrao) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gerando dados aleatórios de modelo de carro para simulação de agrupamento ao usar nosso estimador\n",
    "\n",
    "np.random.seed(SEED)\n",
    "dados['modelo'] = dados.idade_do_modelo + np.random.randint(-2, 3, size=10000)\n",
    "dados.modelo = dados.modelo + abs(dados.modelo.min()) + 1\n",
    "dados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imprime_resultados(results):\n",
    "  media = results['test_score'].mean() * 100\n",
    "  desvio = results['test_score'].std() * 100\n",
    "  print(\"Accuracy médio %.2f\" % media)\n",
    "  print(\"Intervalo [%.2f, %.2f]\" % (media - 2 * desvio, media + 2 * desvio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GroupKFold em um pipeline com StandardScaler e SVC\n",
    "# GroupKFold para analisar como o modelo se comporta com novos grupos\n",
    "\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "SEED = 301\n",
    "np.random.seed(SEED)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "modelo = SVC()\n",
    "\n",
    "pipeline = Pipeline([('transformacao',scaler), ('estimador',modelo)])\n",
    "\n",
    "cv = GroupKFold(n_splits = 10)\n",
    "results = cross_validate(pipeline, x_azar, y_azar, cv = cv, groups = dados.modelo, return_train_score=False)\n",
    "imprime_resultados(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 301\n",
    "np.random.seed(SEED)\n",
    "\n",
    "cv = GroupKFold(n_splits = 10)\n",
    "modelo = DecisionTreeClassifier(max_depth=2)\n",
    "results = cross_validate(modelo, x_azar, y_azar, cv = cv, groups = dados.modelo, return_train_score=False)\n",
    "imprime_resultados(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "\n",
    "modelo.fit(x_azar, y_azar)\n",
    "features = x_azar.columns\n",
    "dot_data = export_graphviz(modelo, out_file=None, filled=True, rounded=True, \n",
    "                class_names=[\"não\", \"sim\"], \n",
    "                feature_names =  features)\n",
    "\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph # Tree01.svg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 301\n",
    "np.random.seed(SEED)\n",
    "\n",
    "cv = GroupKFold(n_splits = 10)\n",
    "modelo = DecisionTreeClassifier(max_depth=3)\n",
    "results = cross_validate(modelo, x_azar, y_azar, cv = cv, groups = dados.modelo, return_train_score=False)\n",
    "imprime_resultados(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 301\n",
    "np.random.seed(SEED)\n",
    "\n",
    "cv = GroupKFold(n_splits = 10)\n",
    "modelo = DecisionTreeClassifier(max_depth=15)\n",
    "results = cross_validate(modelo, x_azar, y_azar, cv = cv, groups = dados.modelo, return_train_score=False)\n",
    "imprime_resultados(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roda_arvore_de_decisao(max_depth):\n",
    "  SEED = 301\n",
    "  np.random.seed(SEED)\n",
    "\n",
    "  cv = GroupKFold(n_splits = 10)\n",
    "  modelo = DecisionTreeClassifier(max_depth=max_depth)\n",
    "  results = cross_validate(modelo, x_azar, y_azar, cv = cv, groups = dados.modelo, return_train_score=True)\n",
    "  train_score = results['train_score'].mean() * 100\n",
    "  test_score = results['test_score'].mean() * 100\n",
    "  # print(\"Arvore max_depth = %d, treino = %.2f, teste = %.2f\" % (max_depth, results['train_score'].mean() * 100, results['test_score'].mean() * 100))\n",
    "  tabela = [max_depth, train_score, test_score]\n",
    "  return tabela\n",
    "  \n",
    "resultados = [roda_arvore_de_decisao(i) for i in range (1, 33)]\n",
    "resultados = pd.DataFrame(resultados, columns = [\"max_depth\", \"train\", \"test\"])\n",
    "resultados.head()\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.lineplot(x = \"max_depth\", y = \"train\", data = resultados)\n",
    "sns.lineplot(x = \"max_depth\", y = \"test\", data = resultados)\n",
    "plt.legend([\"Treino\", \"Teste\"]) # Lineplot.png\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roda_arvore_de_decisao(max_depth, min_samples_leaf):\n",
    "  SEED = 301\n",
    "  np.random.seed(SEED)\n",
    "\n",
    "  cv = GroupKFold(n_splits = 10)\n",
    "  modelo = DecisionTreeClassifier(max_depth=max_depth, min_samples_leaf = min_samples_leaf)\n",
    "  results = cross_validate(modelo, x_azar, y_azar, cv = cv, groups = dados.modelo, return_train_score=True)\n",
    "  train_score = results['train_score'].mean() * 100\n",
    "  test_score = results['test_score'].mean() * 100\n",
    "  # print(\"Arvore max_depth = %d, min_samples_leaf = %d, treino = %.2f, teste = %.2f\" % (max_depth, min_samples_leaf, train_score, test_score))\n",
    "  tabela = [max_depth, min_samples_leaf, train_score, test_score]\n",
    "  return tabela\n",
    "\n",
    "def busca():\n",
    "  resultados = []\n",
    "  for max_depth in range(1,33):\n",
    "    for min_samples_leaf in [32, 64, 128, 256]:\n",
    "        tabela = roda_arvore_de_decisao(max_depth, min_samples_leaf)\n",
    "        resultados.append(tabela)\n",
    "  resultados = pd.DataFrame(resultados, columns= [\"max_depth\",\"min_samples_leaf\",\"train\",\"test\"])\n",
    "  return resultados\n",
    "\n",
    "resultados = busca()\n",
    "resultados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados.sort_values(\"test\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = resultados.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(corr) # Heatmap.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.plotting.scatter_matrix(resultados, figsize = (15, 8), alpha = 0.3) # Scatterplot.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(resultados) # Pairplot.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import ascii_letters\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set(style=\"white\")\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5}) # Heatmap2.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def busca():\n",
    "  resultados = []\n",
    "  for max_depth in range(1,33):\n",
    "    for min_samples_leaf in [128, 192, 256, 512]:\n",
    "        tabela = roda_arvore_de_decisao(max_depth, min_samples_leaf)\n",
    "        resultados.append(tabela)\n",
    "  resultados = pd.DataFrame(resultados, columns= [\"max_depth\",\"min_samples_leaf\",\"train\",\"test\"])\n",
    "  return resultados\n",
    "\n",
    "resultados = busca()\n",
    "resultados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados.sort_values(\"test\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roda_arvore_de_decisao(max_depth, min_samples_leaf, min_samples_split):\n",
    "  SEED = 301\n",
    "  np.random.seed(SEED)\n",
    "\n",
    "  cv = GroupKFold(n_splits = 10)\n",
    "  modelo = DecisionTreeClassifier(max_depth=max_depth, min_samples_leaf = min_samples_leaf, min_samples_split = min_samples_split)\n",
    "  results = cross_validate(modelo, x_azar, y_azar, cv = cv, groups = dados.modelo, return_train_score=True)\n",
    "  fit_time = results['fit_time'].mean()\n",
    "  score_time = results['score_time'].mean()\n",
    "  train_score = results['train_score'].mean() * 100\n",
    "  test_score = results['test_score'].mean() * 100\n",
    "\n",
    "  tabela = [max_depth, min_samples_leaf, min_samples_split, train_score, test_score, fit_time, score_time]\n",
    "  return tabela\n",
    "\n",
    "def busca():\n",
    "  resultados = []\n",
    "  for max_depth in range(1,33):\n",
    "    for min_samples_leaf in [32, 64, 128, 256]:\n",
    "        for min_samples_split in [32, 64, 128, 256]:\n",
    "          tabela = roda_arvore_de_decisao(max_depth, min_samples_leaf, min_samples_split)\n",
    "          resultados.append(tabela)\n",
    "  resultados = pd.DataFrame(resultados, columns= [\"max_depth\",\"min_samples_leaf\", \"min_samples_split\", \"train\",\"test\", \"fit_time\", \"score_time\"])\n",
    "  return resultados\n",
    "\n",
    "resultados = busca()\n",
    "resultados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados.sort_values(\"test\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "SEED=301\n",
    "np.random.seed(SEED)\n",
    "\n",
    "espaco_de_parametros = {\n",
    "    \"max_depth\" : [3, 5],\n",
    "    \"min_samples_split\": [32, 64, 128],\n",
    "    \"min_samples_leaf\": [32, 64, 128],\n",
    "    \"criterion\": [\"gini\", \"entropy\"]\n",
    "\n",
    "}\n",
    "\n",
    "busca = GridSearchCV(DecisionTreeClassifier(),\n",
    "                    espaco_de_parametros,\n",
    "                    cv = GroupKFold(n_splits = 10))\n",
    "\n",
    "busca.fit(x_azar, y_azar,groups = dados.modelo)\n",
    "resultados = pd.DataFrame(busca.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(busca.best_params_)\n",
    "print(busca.best_score_ * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melhor = busca.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score \n",
    "\n",
    "predicoes = melhor.predict(x_azar) \n",
    "accuracy = accuracy_score(predicoes, y_azar) * 100\n",
    "\n",
    "print(\"Accuracy para os dados foi %.2f%%\" % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "SEED=301\n",
    "np.random.seed(SEED)\n",
    "\n",
    "espaco_de_parametros = {\n",
    "    \"max_depth\" : [3, 5],\n",
    "    \"min_samples_split\": [32, 64, 128],\n",
    "    \"min_samples_leaf\": [32, 64, 128],\n",
    "    \"criterion\": [\"gini\", \"entropy\"]\n",
    "\n",
    "}\n",
    "\n",
    "busca = GridSearchCV(DecisionTreeClassifier(),\n",
    "                    espaco_de_parametros,\n",
    "                    cv = KFold(n_splits = 5, shuffle=True))\n",
    "\n",
    "busca.fit(x_azar, y_azar)\n",
    "resultados = pd.DataFrame(busca.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(busca, x_azar, y_azar, cv = KFold(n_splits=5, shuffle=True))\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imprime_score(scores):\n",
    "  media = scores.mean() * 100\n",
    "  desvio = scores.std() * 100\n",
    "  print(\"Accuracy médio %.2f\" % media)\n",
    "  print(\"Intervalo [%.2f, %.2f]\" % (media - 2 * desvio, media + 2 * desvio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "\n",
    "\n",
    "features = x_azar.columns\n",
    "dot_data = export_graphviz(melhor, out_file=None, filled=True, rounded=True,\n",
    "                          class_names=[\"não\",\"sim\"],\n",
    "                          feature_names=features)\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph # Tree02.svg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomizedSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "SEED=301\n",
    "np.random.seed(SEED)\n",
    "\n",
    "espaco_de_parametros = {\n",
    "    \"max_depth\" : [3, 5],\n",
    "    \"min_samples_split\": [32, 64, 128],\n",
    "    \"min_samples_leaf\": [32, 64, 128],\n",
    "    \"criterion\": [\"gini\", \"entropy\"]\n",
    "    \n",
    "}\n",
    "\n",
    "busca = RandomizedSearchCV(DecisionTreeClassifier(),\n",
    "                    espaco_de_parametros, \n",
    "                    n_iter = 16,\n",
    "                    cv = KFold(n_splits = 5),\n",
    "                          random_state = SEED)\n",
    "\n",
    "\n",
    "busca.fit(x_azar, y_azar,groups = dados.modelo)\n",
    "resultados = pd.DataFrame(busca.cv_results_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(busca, x_azar, y_azar, cv = KFold(n_splits=5, shuffle=True))\n",
    "imprime_score(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import randint\n",
    "\n",
    "SEED=301\n",
    "np.random.seed(SEED)\n",
    "\n",
    "espaco_de_parametros = {\n",
    "    \"max_depth\" : [3, 5, 10, 15, 20, 30, None],\n",
    "    \"min_samples_split\" : randint(32, 128),\n",
    "    \"min_samples_leaf\" : randint(32, 128),\n",
    "    \"criterion\" : [\"gini\", \"entropy\"]\n",
    "\n",
    "}\n",
    "\n",
    "busca = RandomizedSearchCV(DecisionTreeClassifier(),\n",
    "                    espaco_de_parametros, \n",
    "                    n_iter = 16,\n",
    "                    cv = KFold(n_splits = 5, shuffle=True),\n",
    "                          random_state = SEED)\n",
    "\n",
    "\n",
    "busca.fit(x_azar, y_azar)\n",
    "resultados = pd.DataFrame(busca.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(busca, x_azar, y_azar, cv = KFold(n_splits=5, shuffle=True))\n",
    "imprime_score(scores)\n",
    "melhor = busca.best_estimator_\n",
    "print(melhor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import time \n",
    "\n",
    "SEED=301\n",
    "np.random.seed(SEED)\n",
    "\n",
    "espaco_de_parametros = {\n",
    "    \"n_estimators\" : [10, 100],\n",
    "    \"max_depth\" : [3, 5],\n",
    "    \"min_samples_split\": [32, 64, 128],\n",
    "    \"min_samples_leaf\": [32, 64, 128],\n",
    "    \"bootstrap\" : [True, False],\n",
    "    \"criterion\": [\"gini\", \"entropy\"]\n",
    "\n",
    "}\n",
    "\n",
    "tic = time.time()\n",
    "busca = GridSearchCV(RandomForestClassifier(),\n",
    "                    espaco_de_parametros,\n",
    "                    cv = KFold(n_splits = 5, shuffle=True))\n",
    "busca.fit(x_azar, y_azar)\n",
    "tac = time.time()\n",
    "tempo_que_passou = tac - tic\n",
    "print(\"Tempo %.2f segundos\" % tempo_que_passou)\n",
    "\n",
    "\n",
    "\n",
    "resultados = pd.DataFrame(busca.cv_results_)\n",
    "\n",
    "resultados_ordenados_pela_media = resultados.sort_values(\"mean_test_score\", ascending=False)\n",
    "for indice, linha in resultados_ordenados_pela_media[:5].iterrows():\n",
    "  print(\"%.3f +-(%.3f) %s\" % (linha.mean_test_score, linha.std_test_score*2, linha.params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import time \n",
    "\n",
    "SEED=301\n",
    "np.random.seed(SEED)\n",
    "\n",
    "espaco_de_parametros = {\n",
    "    \"n_estimators\" : randint(10, 101),\n",
    "    \"max_depth\" : randint(3, 6),\n",
    "    \"min_samples_split\": randint(32, 129),\n",
    "    \"min_samples_leaf\": randint(32, 129),\n",
    "    \"bootstrap\" : [True, False],\n",
    "    \"criterion\": [\"gini\", \"entropy\"]\n",
    "\n",
    "}\n",
    "\n",
    "tic = time.time()\n",
    "busca = RandomizedSearchCV(RandomForestClassifier(),\n",
    "                    espaco_de_parametros,\n",
    "                    n_iter = 80,\n",
    "                    cv = KFold(n_splits = 5, shuffle=True))\n",
    "busca.fit(x_azar, y_azar)\n",
    "tac = time.time()\n",
    "tempo_que_passou = tac - tic\n",
    "print(\"Tempo %.2f segundos\" % tempo_que_passou)\n",
    "\n",
    "\n",
    "\n",
    "resultados = pd.DataFrame(busca.cv_results_)\n",
    "\n",
    "resultados_ordenados_pela_media = resultados.sort_values(\"mean_test_score\", ascending=False)\n",
    "for indice, linha in resultados_ordenados_pela_media[:5].iterrows():\n",
    "  print(\"%.3f +-(%.3f) %s\" % (linha.mean_test_score, linha.std_test_score*2, linha.params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "SEED=301\n",
    "np.random.seed(SEED)\n",
    "\n",
    "x_treino_teste, x_validacao, y_treino_teste, y_validacao = train_test_split(x_azar, y_azar, test_size=0.2, shuffle=True, stratify=y_azar)\n",
    "\n",
    "print(x_treino_teste.shape)\n",
    "print(x_validacao.shape)\n",
    "print(y_treino_teste.shape)\n",
    "print(y_validacao.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "SEED=301\n",
    "np.random.seed(SEED)\n",
    "\n",
    "espaco_de_parametros = {\n",
    "    \"n_estimators\" : randint(10, 101),\n",
    "    \"max_depth\" : randint(3, 6),\n",
    "    \"min_samples_split\": randint(32, 129),\n",
    "    \"min_samples_leaf\": randint(32, 129),\n",
    "    \"bootstrap\" : [True, False],\n",
    "    \"criterion\": [\"gini\", \"entropy\"]\n",
    "\n",
    "}\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits = 1, test_size = 0.25)\n",
    "\n",
    "tic = time.time()\n",
    "busca = RandomizedSearchCV(RandomForestClassifier(),\n",
    "                    espaco_de_parametros,\n",
    "                    n_iter = 5,\n",
    "                    cv = split)\n",
    "busca.fit(x_treino_teste, y_treino_teste)\n",
    "tac = time.time()\n",
    "tempo_que_passou = tac - tic\n",
    "print(\"Tempo %.2f segundos\" % tempo_que_passou)\n",
    "\n",
    "\n",
    "\n",
    "resultados = pd.DataFrame(busca.cv_results_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "scores = cross_val_score(busca, x_validacao, y_validacao, cv = split)\n",
    "tac = time.time()\n",
    "tempo_passado = tac - tic\n",
    "print(\"Tempo %.2f segundos\" % tempo_passado)\n",
    "\n",
    "scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
